{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaccination schedule : comment classification\n",
    "\n",
    "In this notebook we will run the pupeline to classify schedule-related comemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel \"base_clone\"\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time\n",
    "\n",
    "import Schedule_pipeline_functions as SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments processed:  100000\n",
      "Time (min) :  2.5241777737935385\n",
      "\n",
      "Total time (min) :  2.524178226788839\n",
      "Number of matches :  6954\n",
      "\n",
      "Number of comments containing at least one of the keword :  7902\n",
      "Number of unique comments retrieved :  5417\n",
      "\n",
      "Number of matches with \"schedule_noun\" pattern :  3884\n",
      "Number of matches with \"delay_verbs\" pattern :  3070\n"
     ]
    }
   ],
   "source": [
    "# load data in chunks\n",
    "comments_chunks = pd.read_csv('data/sample_of_comments.csv.gz', \n",
    "                                chunksize=10000, compression='gzip')\n",
    "\n",
    "# list of responses (to be transformed in DataFrame)\n",
    "results = []\n",
    "n=0 # comments count\n",
    "n_with_keywords = 0\n",
    "\n",
    "t0 = time.time()\n",
    "t_tot = 0\n",
    "\n",
    "for chunk in comments_chunks:\n",
    "    \n",
    "    n += chunk.shape[0]\n",
    "    \n",
    "    if n%100000 == 0:\n",
    "        print('Comments processed: ', n)\n",
    "        print('Time (min) : ', (time.time() - t0) / 60)\n",
    "        t_tot += time.time() - t0\n",
    "        t0 = time.time()\n",
    "        \n",
    "    # get useful info and drop comments with no text\n",
    "    chunk = chunk[['body', 'comment_author', 'thread_id', 'comment_date', 'c_id']].dropna(subset=['body'])\n",
    "    \n",
    "    # loop over comments\n",
    "    for idx, row in chunk.iterrows():\n",
    "        tx, c_id, comment_author, thread_id, comment_date = row.body, row.c_id, row.comment_author, row.thread_id, row.comment_date\n",
    "        \n",
    "        # has one of the keywords?\n",
    "        n_with_keywords += 0 if (\"schedule\" not in tx and 'spac' not in tx and 'dela' not in tx and 'split' not in tx) else 1\n",
    "        # sent tokenizer for comments\n",
    "        for sent in sent_tokenize(tx):\n",
    "    \n",
    "            # apply first filter\n",
    "            idxs_keywords = SP.first_filter_keywords_syntactic(sent)\n",
    "            # obtain structured representation\n",
    "            representation = SP.Structured_representation(idxs_keywords)\n",
    "            representation = [SP.translate_response(i, c_id, comment_author, thread_id, comment_date) \n",
    "                                                                                      for i in representation]\n",
    "\n",
    "            results.extend(representation)\n",
    "            \n",
    "            \n",
    "results = pd.DataFrame.from_dict(results)\n",
    "\n",
    "\n",
    "columns_ordered = ['sent', 'c_id', 'comment_author', 'thread_id', 'comment_date',\n",
    "                   'pattern_matched', 'text_short', 'negations',\n",
    "                   'amod_subj_xcomp_lemma', 'amod_subj_xcomp_lower', \n",
    "                   'compound_subj_xcomp_lemma', 'compound_subj_xcomp_lower',\n",
    "                   'pos_subj_xcomp_lemma', 'pos_subj_xcomp_lower',\n",
    "                   'subject_xcomp_lemma', 'subject_xcomp_lower',\n",
    "                   'verb_xcomp_lemma', 'verb_xcomp_lower', 'verb_phrase_xcomp', 'verb_tense_xcomp',\n",
    "                   'amod_subj_lemma', 'amod_subj_lower',\n",
    "                   'compound_subj_lemma', 'compound_subj_lower',\n",
    "                   'pos_subj_lemma', 'pos_subj_lower',\n",
    "                   'subject_lemma', 'subject_lower', 'subject_active',\n",
    "                   'verb_lemma', 'verb_lower', 'verb_phrase', 'verb_tense',\n",
    "                   'dobj_amod_lemma', 'dobj_amod_lower',\n",
    "                   'compound_dobj_lemma', 'compound_dobj_lower',\n",
    "                   'pos_dobj_lemma', 'pos_dobj_lower',\n",
    "                   'dobj_lemma', 'dobj_lower']\n",
    "\n",
    "results = results[columns_ordered]\n",
    "results.to_csv(\"output/Vaccination_schedule/Structured_representation_comments_schedule.csv\")\n",
    "           \n",
    "print()\n",
    "print(\"Total time (min) : \", t_tot/60)\n",
    "print(\"Number of matches : \", results.shape[0])\n",
    "print()\n",
    "print('Number of comments containing at least one of the keword : ', n_with_keywords)\n",
    "print(\"Number of unique comments retrieved : \", results.groupby(['c_id', 'comment_author', \n",
    "                                                           'thread_id', 'comment_date']).apply(lambda rows: 1).sum())\n",
    "print()\n",
    "patterns_matched = results.pattern_matched.value_counts()\n",
    "print('Number of matches with \"schedule_noun\" pattern : ', patterns_matched['schedule_noun'])\n",
    "print('Number of matches with \"delay_verbs\" pattern : ', patterns_matched['delay_verbs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>c_id</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>pattern_matched</th>\n",
       "      <th>text_short</th>\n",
       "      <th>negations</th>\n",
       "      <th>amod_subj_xcomp_lemma</th>\n",
       "      <th>amod_subj_xcomp_lower</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_phrase</th>\n",
       "      <th>verb_tense</th>\n",
       "      <th>dobj_amod_lemma</th>\n",
       "      <th>dobj_amod_lower</th>\n",
       "      <th>compound_dobj_lemma</th>\n",
       "      <th>compound_dobj_lower</th>\n",
       "      <th>pos_dobj_lemma</th>\n",
       "      <th>pos_dobj_lower</th>\n",
       "      <th>dobj_lemma</th>\n",
       "      <th>dobj_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>plus he is a brand new baby, i would like to d...</td>\n",
       "      <td>c2420670102</td>\n",
       "      <td>ohbabyLiam</td>\n",
       "      <td>a42201085</td>\n",
       "      <td>05/23/2013</td>\n",
       "      <td>delay_verbs</td>\n",
       "      <td>i would like to delay</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>to delay</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>so far i am only planning on the dtap, polio, ...</td>\n",
       "      <td>c2420670102</td>\n",
       "      <td>ohbabyLiam</td>\n",
       "      <td>a42201085</td>\n",
       "      <td>05/23/2013</td>\n",
       "      <td>delay_verbs</td>\n",
       "      <td>i am spacing them</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>am spacing</td>\n",
       "      <td>PresentContinuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>them</td>\n",
       "      <td>them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>you should post this to the none and selected ...</td>\n",
       "      <td>c2471479210</td>\n",
       "      <td>Rach3740</td>\n",
       "      <td>a52858753</td>\n",
       "      <td>10/09/2014</td>\n",
       "      <td>delay_verbs</td>\n",
       "      <td>delayed</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>delayed</td>\n",
       "      <td>PastParticipe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i found a pedi favorable to selective and dela...</td>\n",
       "      <td>c2471479210</td>\n",
       "      <td>Rach3740</td>\n",
       "      <td>a52858753</td>\n",
       "      <td>10/09/2014</td>\n",
       "      <td>delay_verbs</td>\n",
       "      <td>delay</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>delay</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>japan had the highest incidence in sids until ...</td>\n",
       "      <td>c2063817359</td>\n",
       "      <td>haileycakes</td>\n",
       "      <td>a15243575</td>\n",
       "      <td>09/17/2009</td>\n",
       "      <td>schedule_noun</td>\n",
       "      <td>they delayed their vaccination schedule</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>delayed</td>\n",
       "      <td>PastSimple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vaccination</td>\n",
       "      <td>vaccination</td>\n",
       "      <td>their</td>\n",
       "      <td>their</td>\n",
       "      <td>schedule</td>\n",
       "      <td>schedule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent         c_id  \\\n",
       "0  plus he is a brand new baby, i would like to d...  c2420670102   \n",
       "1  so far i am only planning on the dtap, polio, ...  c2420670102   \n",
       "2  you should post this to the none and selected ...  c2471479210   \n",
       "3  i found a pedi favorable to selective and dela...  c2471479210   \n",
       "4  japan had the highest incidence in sids until ...  c2063817359   \n",
       "\n",
       "  comment_author  thread_id comment_date pattern_matched  \\\n",
       "0     ohbabyLiam  a42201085   05/23/2013     delay_verbs   \n",
       "1     ohbabyLiam  a42201085   05/23/2013     delay_verbs   \n",
       "2       Rach3740  a52858753   10/09/2014     delay_verbs   \n",
       "3       Rach3740  a52858753   10/09/2014     delay_verbs   \n",
       "4    haileycakes  a15243575   09/17/2009   schedule_noun   \n",
       "\n",
       "                                text_short  negations amod_subj_xcomp_lemma  \\\n",
       "0                    i would like to delay          1                   NaN   \n",
       "1                        i am spacing them          1                   NaN   \n",
       "2                                  delayed          1                   NaN   \n",
       "3                                    delay          1                   NaN   \n",
       "4  they delayed their vaccination schedule          1                   NaN   \n",
       "\n",
       "  amod_subj_xcomp_lower  ... verb_phrase         verb_tense dobj_amod_lemma  \\\n",
       "0                   NaN  ...    to delay           Infinite             NaN   \n",
       "1                   NaN  ...  am spacing  PresentContinuous             NaN   \n",
       "2                   NaN  ...     delayed      PastParticipe             NaN   \n",
       "3                   NaN  ...       delay           Infinite             NaN   \n",
       "4                   NaN  ...     delayed         PastSimple             NaN   \n",
       "\n",
       "  dobj_amod_lower compound_dobj_lemma compound_dobj_lower pos_dobj_lemma  \\\n",
       "0             NaN                 NaN                 NaN            NaN   \n",
       "1             NaN                 NaN                 NaN            NaN   \n",
       "2             NaN                 NaN                 NaN            NaN   \n",
       "3             NaN                 NaN                 NaN            NaN   \n",
       "4             NaN         vaccination         vaccination          their   \n",
       "\n",
       "  pos_dobj_lower dobj_lemma dobj_lower  \n",
       "0            NaN        NaN        NaN  \n",
       "1            NaN       them       them  \n",
       "2            NaN        NaN        NaN  \n",
       "3            NaN        NaN        NaN  \n",
       "4          their   schedule   schedule  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER & CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered out matches :  2562\n",
      "Number of filtered in matches :  4392\n",
      "Number of matches filtered in \"schedule_noun\" pattern :  2467\n",
      "Number of matches filtered in \"delay_verbs\" pattern :  1925\n",
      "\n",
      "Number of matches labeled as \"recommended\" :  1603\n",
      "Number of matches labeled as \"alternative\" :  2789\n",
      "\n",
      "Number of unique comments filtered in :  3744\n"
     ]
    }
   ],
   "source": [
    "# here the new column \"FILTER\" corresponds to the final classification (+1 and -1) or \"FILTERED_OUT\"\n",
    "results.loc[:, 'FILTER'] = results.apply(lambda row: SP.Filter(row), axis=1)\n",
    "\n",
    "# remove filtered out matches\n",
    "results_filtered_out = results[results.FILTER=='FILTERED_OUT']\n",
    "results = results[results.FILTER!='FILTERED_OUT']\n",
    "\n",
    "n_reg_modif = results.FILTER.value_counts()\n",
    "patterns_matched = results.pattern_matched.value_counts()\n",
    "\n",
    "print('Number of filtered out matches : ', results_filtered_out.shape[0])\n",
    "print('Number of filtered in matches : ', results.shape[0])\n",
    "print('Number of matches filtered in \"schedule_noun\" pattern : ', patterns_matched['schedule_noun'])\n",
    "print('Number of matches filtered in \"delay_verbs\" pattern : ', patterns_matched['delay_verbs'])\n",
    "print()\n",
    "print('Number of matches labeled as \"recommended\" : ', n_reg_modif[1])\n",
    "print('Number of matches labeled as \"alternative\" : ', n_reg_modif[-1])\n",
    "print()\n",
    "print(\"Number of unique comments filtered in : \", results.groupby(['c_id', 'comment_author', \n",
    "                                                           'thread_id', 'comment_date']).apply(lambda rows: 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGING tense to verbs whose lemma is \"split\". Number of matches changed :  46\n",
      "\n",
      "DISCARDING past tenses. Number of matches removed :  1073\n",
      "\n",
      "CHECK COMMENTS WITH DISCORDANT LABELS\n",
      "Number unique comments  2956\n",
      "\n",
      "Number comments with more classes  317\n",
      "Number comments with more classes and homogeneous  212\n",
      "Number comments with more classes and discordant  105\n"
     ]
    }
   ],
   "source": [
    "# change tense of split (it is almost always considered as PastSimple, I change to PresetsSimple)\n",
    "index_of_comments_split_past = results[(results.verb_lemma=='split')\n",
    "                                      &(results.verb_tense=='PastSimple')\n",
    "                                      &(results.verb_phrase=='split')].index\n",
    "\n",
    "results.loc[index_of_comments_split_past, 'verb_tense'] = 'PresentSimple'\n",
    "print('CHANGING tense to verbs whose lemma is \"split\". Number of matches changed : ', len(index_of_comments_split_past))\n",
    "print()\n",
    "\n",
    "# discard past tenses\n",
    "tense_not_to_take = ['PastSimple', 'PastPassive', 'PastContinuous', 'PastPerfect']\n",
    "\n",
    "n_results = results.shape[0]\n",
    "results = results[(~results.verb_tense.isin(tense_not_to_take))\n",
    "                 &(~results.verb_tense_xcomp.isin(tense_not_to_take))]\n",
    "print('DISCARDING past tenses. Number of matches removed : ', n_results-results.shape[0])\n",
    "print()\n",
    "\n",
    "# check how many comments have discordant labels\n",
    "n_with_more_class = 0\n",
    "n_with_same_class = 0\n",
    "n_classes = []\n",
    "\n",
    "for idx, rows in results.groupby(['c_id', 'comment_author', 'thread_id', 'comment_date']):\n",
    "    \n",
    "    n_classes.append(rows.shape[0])\n",
    "    \n",
    "    if rows.shape[0] > 1:\n",
    "        n_with_more_class+=1\n",
    "        \n",
    "        if len(set(rows.FILTER.values))==1:\n",
    "            n_with_same_class+=1\n",
    "            \n",
    "print('CHECK COMMENTS WITH DISCORDANT LABELS')\n",
    "print('Number unique comments ', len(n_classes))\n",
    "print()\n",
    "print('Number comments with more classes ', n_with_more_class)\n",
    "print('Number comments with more classes and homogeneous ', n_with_same_class)\n",
    "print('Number comments with more classes and discordant ', n_with_more_class-n_with_same_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded comments with discordant labels\n",
      "Final number of schedule-related comments :  2851\n",
      "Number of comments coded as \"recommended\" :  1058\n",
      "Number of comments coded as \"alternative\" :  1793\n"
     ]
    }
   ],
   "source": [
    "# discard comments with discordant labels and assign class for each comment\n",
    "comments_classified = results.groupby(['c_id', 'comment_author', 'thread_id', 'comment_date']).filter(lambda rows:\n",
    "                                                                      len(set(rows.FILTER.values))==1)\n",
    "\n",
    "comments_classified = comments_classified.groupby(['c_id', 'comment_author', \n",
    "                                                   'thread_id', 'comment_date']).apply(lambda rows: \n",
    "                                            pd.Series({'CLASS':list(set(rows.FILTER.values))[0]})).reset_index()\n",
    "\n",
    "print('Discarded comments with discordant labels')\n",
    "print('Final number of schedule-related comments : ', comments_classified.shape[0])\n",
    "n_reg_modif = comments_classified.CLASS.value_counts()\n",
    "print('Number of comments coded as \"recommended\" : ', n_reg_modif[1])\n",
    "print('Number of comments coded as \"alternative\" : ', n_reg_modif[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>c2000186919</td>\n",
       "      <td>Virgo&amp;SparklerMomma</td>\n",
       "      <td>a87195</td>\n",
       "      <td>03/21/2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>c2000274000</td>\n",
       "      <td>mlbryant_7</td>\n",
       "      <td>a124485</td>\n",
       "      <td>04/04/2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>c2000380950</td>\n",
       "      <td>pineaple35</td>\n",
       "      <td>a167455</td>\n",
       "      <td>04/16/2008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>c2000840633</td>\n",
       "      <td>Conshusmama</td>\n",
       "      <td>a363035</td>\n",
       "      <td>05/24/2008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>c2000841389</td>\n",
       "      <td>~domestic&amp;tattooed~</td>\n",
       "      <td>a363035</td>\n",
       "      <td>05/24/2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_id       comment_author thread_id comment_date  CLASS\n",
       "0  c2000186919  Virgo&SparklerMomma    a87195   03/21/2008      1\n",
       "1  c2000274000           mlbryant_7   a124485   04/04/2008      1\n",
       "2  c2000380950           pineaple35   a167455   04/16/2008     -1\n",
       "3  c2000840633          Conshusmama   a363035   05/24/2008     -1\n",
       "4  c2000841389  ~domestic&tattooed~   a363035   05/24/2008      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_classified.to_csv(\"output/Vaccination_schedule/comments_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 base_clone",
   "language": "python",
   "name": "base_clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
